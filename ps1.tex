\documentclass{article}
\usepackage{amsmath}
\newcommand{\matr}[1]{\mathbf{#1}}

\begin{document}
\pagenumbering{arabic}
\section{Simple Matrix Problems}
	\subsection{} % 1.a
	This would only work in a column vector with a same size. Let's say it's a size-N vector.

	\begin{equation*}
	vec(\matr{a} \times \matr{b^{T}}) = b \otimes a
	\end{equation*}

	$\matr{a} \times \matr{b^{T}}$ would have 

	\subsection{} % 1.b

	\begin{equation*}
	vec(\matr{A})^{T} * vec(\matr{B}) = \matr{tr(\matr{A^{T}}*\matr{B})} 
	\end{equation*}	
	
	Left side is going to equal to a sum of multiples of all elements at their respective position.

	\begin{equation*}
	\begin{bmatrix}
	A_{11} \ A_{21} \ ... \ A_{1n} \ A_{21} \ A_{22}  \ ... \ A_{2n} \ ... \ A{mn}
	\end{bmatrix}
	*
	\begin{bmatrix}
	B_{11} \\ B_{21} \\ ... \\ B_{1n} \\ B_{21} \\ B_{22}  \\ ... \\ B_{2n} \\ ... \\ B{mn}
	\end{bmatrix}
	\end{equation*}

	Right side, the trace operation is going to sum up all the diagonal entries. $\matr{tr(\matr{A^{T}}*\matr{B})}$
	ends up something like this:\\
	$\matr{A_{11}B_{11}} + \matr{A_{21}B_{21}} + ... + \matr{A_{1n}B_{1n}} + \matr{A_{12}B_{12}} + ... + \matr{A_{mn}B_{mn}}$\\
	\\
	They are equivalent.

	\subsection{} % 1.c
	$\matr{{x}^{T}} \matr{A} \matr{A}^{T} \matr{x}$ is equivalent to $\matr{(A^{T}x)^{T}}\matr{(A^{T}x)}$ which equals to 
	norm of $\matr{(A^{T}x)}$. Which is always larger than 0. So, this is positive semi-definite.

\section {Probability}
	$P(B) = 0.7\%$\\
	$P(M \mid B) = 90\%$\\
	$P(M \mid \neg B) = 8\%$\\
	$P(M)  = \frac{P(MB) P(B)}{P(B)} \ + \frac{P(M \neg B) P(\neg B)}{P(\neg B)}  = 0.7\% * 90\% + 8\% * 99.3\%\\$
	$P(B \mid M)  = \frac{P(M \mid B) P(B)}{P(M)} = \frac{90\% * 0.7\%}{8.475\%} = \mathbf{7.34\%}$

\section {Problem 3}
	\subsection{Matrix Version} % 3.1
		\subsubsection{} % 3.1.a

		We start with a (M x N) by K matrix. Let's define few things:\\
		- $\matr{[1]_{n}}$ is a column vector with a size of n.\\
		- Our image matrix is called $\matr{img}$\\
		\\
		The following operation would get the mean image in M by N format:\\	
		\begin{equation*}
		\frac{(\matr{img}*\matr{[1]_{K}})^{\{M\}}}{K}
		\end{equation*}
		\\
		Multiplying the matrix of column image vectors with column of 1s would result in a summation of each image.
		Reshaping this sum would result in M by N image and dividing by K would return a mean image.
		\\

		\subsubsection{The hard one} % 3.1.b
		The Problem is in two steps. We have to come up with a matrix with a size of 2 by K.
		This matrix would have column vectors where the entries are average of top and average of bottom of each image.\\
		\\
		Let's name this matrix $\matr{X}$. Here's how to get $\matr{X}$:\\
		\\
		1. Transpose $\matr{img}$. This would result in K by (M x N) matrix.\\
		\\
		2. Multiply $\matr{img}^{T}$ with $(\matr{[1]^{T}_{M/2}} \otimes \matr{I} \otimes \matr{[1]^{T}_{N}})^{T}$\\
		\\
		This would result in a sum of all the K by 2 matrix where each row vector is a sum of tops and sum of bottoms of each image.\\
		\\
		3. Transpose the product so that it would be in 2 by K format.\\
		\\
		4. Divide the transpose of the product by $\frac{M}{2} \times N$ to get the average.\\
		\\
		Cool. Let's define another matrix $\matr{Y}$.  \\
		This matrix equals to $\matr{X} - \matr{X} \times \matr{[1]^{T}_{K}} \otimes  
		\begin{bmatrix}
		{\frac{1}{K} \ \frac{1}{K}}
		\end{bmatrix}^{T}
		$ which is a mean-subtracted $\matr{X}$.\\
		\\
		Our final covariance matrix is then $\frac{1}{K}\matr{Y}\matr{Y}^{T}$

	\subsection{4D Tensor Version} % 3.2
		\subsubsection{} % 3.2.a
		We start with a 4D tensor with dimension of M X N 3 X K. Let's name this img. 
		We'll begin our series of operations with applying vec() on our tensor.\\

		\begin{equation*}
		\matr{A} = vec(img)
		\end{equation*}

		Now vec(img) is going to return a A, a matrix of size (M X N X 3) by K. We are going to multiply this with K by 1 column vector of 1s. 
		This would return sum of all images at their respective pixel and channel.

		\begin{equation*}
		\matr{V_{RGB}} = \matr{A} * 
						\begin{bmatrix} 
						1 \\ 1 \\ ... \\ K 
						\end{bmatrix} 
		\end{equation*}	
		
		So now we have $\matr{V_{RGB}}$ which is a sum of all images at their respectivel pixel and channel. We need to reshape this so that
		we have (M X N) by 3 matrix. This matrix would have M x N image but color-sorted in each column.  
		We can then multiply by a column vector of 1s similar to what we did before to sum up each pixel over all color channels. \\
		\\
		We'll do this by using vec-transposing by M*N and then multiplying by a column of 1s with size of 3 by 1

		\begin{equation*}
		\matr{V_{Greyscale}} = \matr{V_{RGB}}^{\{ M*N \}} * 
						\begin{bmatrix} 
						1 \\ 1 \\ 1  
						\end{bmatrix} 
		\end{equation*}	

		Now we have a (M X N) column vector with each pixel summed over all images and color. We need to divide this by 3 * K to get the mean
		image.

		\begin{equation*}
		\matr{V_{\mu}} = \matr{V_{Greyscale}} / (3*K) 
		\end{equation*}	

		We are done.

		\subsubsection{} % 3.2.b
	
		We start once again with applying vec() on our tensor.\\

		\begin{equation*}
		\matr{A} = vec(img)
		\end{equation*}

		Again, vec(img) is going to return a A, a matrix of size (M X N X 3) by K. We are going to multiply this with K by 1 column vector of 1s. 
		This would return sum of all images at their respective pixel and channel.

		\begin{equation*}
		\matr{V_{RGB}} = \matr{A} * 
						\begin{bmatrix} 
						1 \\ 1 \\ ... \\ K 
						\end{bmatrix} 
		\end{equation*}	
		
		So now we have $\matr{V_{RGB}}$ which is a sum of all images at their respectivel pixel and channel. We'll transpose this so that
		each column would have 
	We need to reshape this so that
		we have (M X N) by 3 matrix. This matrix would have M x N image but color-sorted in each column.  
		We can then multiply by a column vector of 1s similar to what we did before to sum up each pixel over all color channels. \\
		\\
		We'll do this by using vec-transposing by M*N and then multiplying by a column of 1s with size of 3 by 1

		\begin{equation*}
		\matr{V_{Greyscale}} = \matr{V_{RGB}}^{\{ M*N \}} * 
						\begin{bmatrix} 
						1 \\ 1 \\ 1  
						\end{bmatrix} 
		\end{equation*}	
		
		//But we'll transpose the matrix, so all the red channel would be on one column. Blue on other and so on. 
		
\section{This problem was good}
	We are given a vector X and we are supposed to come up with a matrix that when multiplied that returns a vec-operated coefficient matrix.\\
	This is a two step process:\\
	\\
	1. We need to apply a Hann Window on each frame\\
	2. Calculate DFT coefficients.\\
	\\
	The number of frames we are going to get with an hop size of 512 and frame size of 2014 is ceiling of (Length of Sample - 1024) / 512 + 1.
	So we are going to have a (Number of Frames * Frame size) by Length of Sample matrix which is going to consist of mostly zeros but copy of 				diagnolized hanning window of size 1024 shifting by 512 columns every 1024 row. Multiplying our sample with this matrix would effectively split the 			sample by frames and apply window.
	\\
	Once that's done, we just apply DFT by multiplying $\matr{I_{Number of Frames}} \otimes$  DFT matrix of size of 1024 by 1024. with our previous 			Hanning matrix.\\
	\\
	To get the spectogram, we just vec-transpose our matrix by 1024. Throw away rows above 1024/2 + 1 since they are repeated and plot their absolute 		value.\\
	\\
	Following is my implementation of this idea with the complete DFT matrix and a sample spectogram of dense mixture of detuned saw waves, i.e. 			supersaw wave.

	\end{document}